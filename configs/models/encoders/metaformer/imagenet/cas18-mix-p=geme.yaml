patch_size: [4, 4]

emb_dims: [64, 128, 320, 512]
depths: [3, 3, 9, 3]

stem: {name: single_conv}

poolings:
  - {name: conv, kernel_size: 3, stride: 2, padding: 1}
  - {name: conv, kernel_size: 3, stride: 2, padding: 1}
  - {name: geme}

token_mixers:
  - {name: conv}
  - {name: conv}
  - {name: attention}
  - {name: attention}

norm_spatial: false
drop_path: 0.15