patch_size: [4, 4]

emb_dims: [128, 256, 512, 768]
depths: [3, 12, 18, 3]

stem: {name: linear}

poolings:
  - {name: conv, kernel_size: 2, stride: 2, padding: 0}
  - {name: conv, kernel_size: 2, stride: 2, padding: 0}
  - {name: geme}

token_mixers:
  - {name: conv}
  - {name: conv}
  - {name: attention}
  - {name: attention}

norm_spatial: false
drop_path: 0.6