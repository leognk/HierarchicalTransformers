patch_size: [4, 4]

emb_dims: [128, 256, 512, 768]
depths: [3, 12, 18, 3]

stem: {name: single_conv}

poolings:
  - {name: conv, kernel_size: 3, stride: 2, padding: 1}
  - {name: conv, kernel_size: 3, stride: 2, padding: 1}
  - {name: conv, kernel_size: 3, stride: 2, padding: 1}

token_mixers:
  - {name: conv}
  - {name: conv}
  - {name: attention}
  - {name: attention}

norm_spatial: false
drop_path: 0.6