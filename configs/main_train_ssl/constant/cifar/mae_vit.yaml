use_wandb: true

dataset:
  config_dir: cifar10
  config: full.yaml
  transform:
    train:
      config: rand_crop.yaml
    eval:
      config: no_aug.yaml

model:
  config_dir: mae_vit
  config: cifar/c1.yaml

optimizer:
  config_dir: adamw
  config: b2=0.95.yaml
  lr:
    scale_with_batch: true
    lr: 1e-3
    decay:
      use: true
      warmup_epochs: 40
      epochs: null
      min: 0
      layer_decay: null
  weight_decay: 0.05

n_epochs: 800
batch_size:
  train: # tot % (per_wrk * n_wrk) = 0
    total: 512
    per_worker: 256
  eval:
    per_worker: 512